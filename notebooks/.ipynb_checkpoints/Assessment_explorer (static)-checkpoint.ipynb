{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0594fe63-967d-4316-a734-d2d9f416ea69",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Static exploration tool for assessment schemes in ICNIRP 2020 and RPS S-1\n",
    "author: Dr Vitas Anderson (*Two Fields Consulting*)\n",
    "\n",
    "date: 9/9/2021\n",
    "\n",
    "To use this Jupyter notebook, run each code cell in succession by either pressing the triangular play button ► in the menu bar above or by pressing SHIFT-ENTER for successive code cells. You can play around with the code as much as you like - it won't affect the original notebook.\n",
    "\n",
    "The notebook contains a function, `calc_ass`, which calculates limit-normalised exposure assessments from two RF sources for the following assessment schemes:\n",
    "\n",
    "+ **Lwbps**: whole body point spatial (the scheme which is currently used for EME calcuated assessments)\n",
    "+ **Llocps**: local point spatial\n",
    "+ **Lwbsa**: whole body spatial average (as now required for whole body exposure to E/H/S in ICNIRP 2020 and RPS S-1)\n",
    "+ **Lwbpssa**: a point spatial representation of the whole body spatial average\n",
    "\n",
    "The assessments are conducted on artificial RF limit-normalised power density exposure distributions using the following formula:\n",
    "\n",
    "$\\Large L_{wbps} = \\frac{k_1}{\\textrm{cosh}(k_2(z-z_{source}))}$\n",
    "\n",
    "where:\n",
    "\n",
    "+ $z$ is the height of the evaluation point\n",
    "+ $z_{source}$ is the height of the RF source\n",
    "+ $k_1$ is a parameter to vary the level of the source field\n",
    "+ $k_2$ is a parameter to vary the vertical beam width of the source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6067ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7836539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from collections import namedtuple\n",
    "from collections.abc import Iterable\n",
    "pd.options.display.max_rows = 201\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f31d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99611d0d-05cc-412a-9873-e3a9d154dba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list(obj):\n",
    "    '''make sure obj is a list'''\n",
    "    if isinstance(obj, Iterable):\n",
    "        return list(obj)\n",
    "    else:\n",
    "        return [obj]    \n",
    "\n",
    "def check_source_inputs(*sources, n=None):\n",
    "    '''Make sure that all source inputs are lists which are of the same length\n",
    "       and are of length n if n is specified'''\n",
    "    sources = [make_list(source) for source in sources]\n",
    "    len_sources = [len(source) for source in sources]\n",
    "    errmsg = f'All source inputs {sources} must have the same number of elements'\n",
    "    assert len(set(len_sources)) == 1, errmsg\n",
    "    if n != None:\n",
    "        errmsg = f'All k1s, k2s, zs source inputs {sources} must each have {n} elements'\n",
    "        assert len_sources[0] == n, errmsg\n",
    "    \n",
    "    return sources\n",
    "\n",
    "def check_dz(dz,h,zlow,zhigh):\n",
    "    '''Check that dz is a valid input'''\n",
    "    # check that the z range is divisible by dz\n",
    "    zrange = zhigh - zlow\n",
    "    nz = int(zrange/dz)   # number of dz intervals in z range\n",
    "    assert nz == zrange/dz, f\"z range ({zrange}) must be divisible by dz ({dz})\"\n",
    "    \n",
    "    # check that spatial average window length is divisible by dz\n",
    "    nh = int(h/dz)    # number of dz intervals within spatial averaging window    \n",
    "    nh2 = int(nh/2)   # number of dz intervals between the centre and the end of the spatial averaging window\n",
    "    assert nh == h/dz, f\"h ({h}) must be divisible by dz ({dz})\"  \n",
    "\n",
    "    return nz, nh, nh2\n",
    "    \n",
    "def calc_z(zlow, zhigh, nz):\n",
    "    '''Calculate the z distribution'''\n",
    "    z = np.linspace(zlow, zhigh, nz+1)\n",
    "    return z\n",
    "\n",
    "def calc_Lwbps(k1s,k2s,zs,z,nz):\n",
    "    '''Calculate the whole body point spatial distribution for limit normalised exposure (Lwbps)'''\n",
    "    Lwbps = np.zeros(nz+1)                  # initialise Lwbps array with zeros\n",
    "    for k1i, k2i, zi in zip(k1s, k2s, zs):  # loop through each source\n",
    "        Lwbps += k1i / np.cosh(k2i*(z-zi))    # add limit normalized field level for each source\n",
    "    return Lwbps\n",
    "\n",
    "def calc_Llocps(Lwbps, fMHz):\n",
    "    '''Calculate the local point spatial distribution for limit normalised exposure (Llocps)'''\n",
    "    # Calculate the local limit multiplier factor\n",
    "    if fMHz <= 400:\n",
    "        m = 5\n",
    "    elif fMHz < 2000:\n",
    "        m = 11.47459891 * fMHz**-0.138646884\n",
    "    else:\n",
    "        m = 4\n",
    "        \n",
    "    # Calculate and return Llocps\n",
    "    return Lwbps / m\n",
    "\n",
    "def calc_valid_nsap(nh, n=None):\n",
    "    '''Return list of no more than n valid numbers of spatial averaging points\n",
    "       for any value of nh, the number of dz intervals in h\n",
    "       If n = None, then show all valid numbers of spatial averaging points'''\n",
    "    valid_nsap = [i+1 for i in range(1, nh+1) if (nh % i == 0)]\n",
    "    if (n != None) and (len(valid_nsap) > n):\n",
    "        valid_nsap = valid_nsap[:n]\n",
    "    return valid_nsap\n",
    "\n",
    "def calc_hindices(nh, nh2, nsap):\n",
    "    '''Determine the array indices of the spatial averaging points\n",
    "       relative to the assessment point'''\n",
    "    dh = int(nh / (nsap-1))  # number of indices between spatial averaging points\n",
    "    hindices = [-nh2 + i*dh for i in range(nsap)]\n",
    "    hindices = np.array(hindices, dtype=int)  # convert list to numpy integer array\n",
    "    return hindices\n",
    "\n",
    "def calc_Lwbsa(Lwbps, nz, nh2, hindices):\n",
    "    '''Calculate the whole body spatial average distribution (Lwbsa)'''   \n",
    "    # initialise Lwbsa array with NaN's (Not a Number)\n",
    "    Lwbsa = np.repeat(np.nan, nz+1)\n",
    "    \n",
    "    # calculate the mean value of Lwbps at the spatial averaging points\n",
    "    for iz in range(nh2, nz-nh2+1):\n",
    "        Lwbsa[iz] = Lwbps[hindices + iz].mean()\n",
    "        \n",
    "    return Lwbsa\n",
    "    \n",
    "def calc_Lwbpssa(Lwbsa, nz, nh, nh2):\n",
    "    '''Calculate the point spatial representation of the wb spatial average (Lwbpssa)\n",
    "    INPUTS:\n",
    "       Lwbsa = spatial average of the whole body limit normalised point spatial field over a vertical line\n",
    "       nz = number of dz intervals in the z range\n",
    "       nh = number of dz intervals in the h averaging window\n",
    "       nh2 = number of dz intervals in half of the h averaging window\n",
    "    OUTPUTS:\n",
    "       Lwbpssa = point spatial respresentation of the spatially averaged field (Lwbsa)\n",
    "       '''\n",
    "    # initialise Lwbpssa array with NaN's (Not a Number)\n",
    "    Lwbpssa = np.repeat(np.nan, nz+1)\n",
    "    \n",
    "    # first pass: assign Lwbpssa values based on minimum value of points that\n",
    "    # are half an averaging window above or below the assessment point\n",
    "    for iz in range(nh, nz-nh+1):\n",
    "        Lwbpssa[iz] = Lwbsa[[iz-nh2, iz+nh2]].min() \n",
    "    \n",
    "    # second pass: assign Lwbsa value at the point(s) where Lwbsa peaks,\n",
    "    # i.e. where spatial averaging window exposure changes between head and feet\n",
    "    ipeaks, _ = find_peaks(Lwbsa)  # get indices of local peaks of Lwbsa values    \n",
    "    for iz in ipeaks:\n",
    "        Lwbpssa[iz] = Lwbsa[iz]\n",
    "        \n",
    "    # third pass: assign minimum Lwbsa value for the length of the spatial averaging window\n",
    "    # where Lwbsa is a minimum\n",
    "    itroughs, _ = find_peaks(1/Lwbsa)  # get indices of local minimums of Lwbsa values\n",
    "    for iz in itroughs:\n",
    "        Lwbpssa[(iz-nh2):(iz+nh2)] = Lwbsa[iz]\n",
    "        \n",
    "    return Lwbpssa  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378e915d-5dc0-4412-92f4-cf4ea61388c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ass(h,nsap,fMHz,zlow,zhigh,dz,k1s,k2s,zs):\n",
    "    '''Function which calculates assessment distributions over a set z height range for:\n",
    "       + point spatial limit normalised field values for whole body exposure (Lwbps)\n",
    "       + point spatial limit normalised field values for local exposure (Llocps)\n",
    "       + spatial average of the whole body Lwbps points (Lwbsa) over a vertical line\n",
    "       + point spatial representation of the whole body spatial averages (Lwbpssa)\n",
    "       \n",
    "       FUNCTION INPUTS:       \n",
    "          h = height of the spatial averaging window (m)\n",
    "       nsap = number of spatial averaging points [3 or 5]\n",
    "       fMHz = exposure frequency in MHz\n",
    "       zlow = lower bound of the z points (m)\n",
    "      zhigh = upper bound of the z points (m)\n",
    "        k1s = list of k1 parameters that set the peak level of the Lps distribution, \n",
    "              e.g. 2 for a single source or [2,1] for two sources\n",
    "        k2s = list of k2 parameters that set the vertical beamwidth of the Lps distribution\n",
    "              e.g. 1 for a single source or [1,2] for two sources\n",
    "        zs = list of heights (m) for the source(s), \n",
    "              e.g. 7 for a single source, or [10,13] for two sources\n",
    "         \n",
    "       FUNCTION OUTPUTS:\n",
    "         a named tuple, L, containing:\n",
    "           + title: an informative title for the assessment\n",
    "           + fMHz: exposure frequency in MHz\n",
    "           + labels: lables for each calculated distribution\n",
    "           + z: the z distribution points for the assessment\n",
    "           + zlow: the lower bound of the z distribution\n",
    "           + zhigh: the upper bound of the z distribution\n",
    "           + lass: a named tuple for the calculated assessments (Lwbps, Llocps, Lwbsa, Lwbpssa)\n",
    "           + nh: number of points in teh vertical averaging window\n",
    "           + df: a pandas dataframe for z and Lwbps, Llocps, Lwbsa, Lwbpssa\n",
    "      '''     \n",
    "    \n",
    "    # Check that all source inputs are lists which are of the same length\n",
    "    k1s,k2s,zs = check_source_inputs(k1s,k2s,zs)\n",
    "    \n",
    "    # Check that the dz value is valid for h and the z range\n",
    "    nz, nh, nh2 = check_dz(dz,h,zlow,zhigh)\n",
    "    \n",
    "    # Check that the nsap input is valid for the number of h points\n",
    "    valid_nsap = calc_valid_nsap(nh)\n",
    "    assert nsap in valid_nsap, f'Value of nsap ({nsap}) must be one of {valid_nsap}'\n",
    "    \n",
    "    # Calculate the z points\n",
    "    z = calc_z(zlow,zhigh,nz)\n",
    "    \n",
    "    # Calculate the whole body point spatial distribution for limit normalised exposure (Lwbps)\n",
    "    Lwbps = calc_Lwbps(k1s,k2s,zs,z,nz)\n",
    "    \n",
    "    # Calculate the local point spatial distribution for limit normalised exposure (Llocps)\n",
    "    Llocps = calc_Llocps(Lwbps, fMHz)\n",
    "    \n",
    "    # Calculate the whole body spatial average distribution (Lwbsa)\n",
    "    hindices = calc_hindices(nh, nh2, nsap)\n",
    "    Lwbsa = calc_Lwbsa(Lwbps, nz, nh2, hindices)\n",
    "    \n",
    "    # Calculate the point spatial representation of the wb spatial average (Lwbpssa)\n",
    "    Lwbpssa = calc_Lwbpssa(Lwbsa, nz, nh, nh2)\n",
    "            \n",
    "    ## Create a pandas dataframe of z and all assessment distributions\n",
    "    df = pd.DataFrame(dict(z=z,Lwbps=Lwbps,Llocps=Llocps,Lwbsa=Lwbsa,Lwbpssa=Lwbpssa))\n",
    "    \n",
    "    ## Create labels for the limit normalised assessment distributions\n",
    "    labels = ['wb point spatial',\n",
    "              'local point spatial',\n",
    "              'wb spatial average',\n",
    "              'wb point spatial spat. avg.']\n",
    "    \n",
    "    ## Create a title for the data set\n",
    "    title = f'{nsap} points over {h}m\\n' + '$k_1$' + f'={\",\".join(map(str,k1s))}, ' + '$k_2$' + f'={\",\".join(map(str,k2s))}, f={fMHz} MHz'\n",
    "    \n",
    "    ## Create a named tuple for all the L assessment distributions\n",
    "    Lass = namedtuple(\"Lass\", \"Lwbps, Llocps, Lwbsa, Lwbpssa\")\n",
    "    lass = Lass(Lwbps, Llocps, Lwbsa, Lwbpssa)\n",
    "    \n",
    "    ## Create a named tuple for all the output data\n",
    "    Ldata = namedtuple(\"Ldata\", \"title fMHz labels z zlow zhigh lass nh df\")\n",
    "    ldata = Ldata(title, fMHz, labels, z, zlow, zhigh, lass, nh, df)\n",
    "\n",
    "    return ldata\n",
    "\n",
    "def plotL(L):\n",
    "    '''Plot the L distributions'''\n",
    "    fig, ax = plt.subplots(figsize=(4,8))\n",
    "    for lass, label in zip(L.lass, L.labels):\n",
    "        ax.plot(lass, L.z, alpha=0.6, label=label)\n",
    "    ax.set_xlabel('Limit normalised field value')\n",
    "    ax.set_ylabel('z (m)')\n",
    "    ax.grid(ls='--')\n",
    "    ax.legend()\n",
    "    zmin, zmax = int(L.zlow), int(L.zhigh)\n",
    "    ax.set_yticks(range(zmin,zmax))\n",
    "    ax.set_ylim(zmin,zmax)\n",
    "    ax.set_title(L.title)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80e348c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vary $k_1$ and $k_2$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f4e279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e840fd49b3224e59a77514065aadc62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1,4,figsize=(9,8))\n",
    "for j, (k1,k2) in enumerate(zip([1,1,1,2],[0.5,1,2,1])):\n",
    "    \n",
    "    # Calculate the assesments\n",
    "    L = calc_ass(h=2, nsap=5, fMHz=400,\n",
    "                 zlow=0, zhigh=20, dz=0.1,\n",
    "                 k1s=k1, k2s=k2, zs=10\n",
    "                )\n",
    "    \n",
    "    # Create the plots\n",
    "    ax = axes[j]\n",
    "    ax.plot(L.lass.Lwbps, L.z, alpha=0.7, label=L.labels[0])\n",
    "    ax.set_xlabel('Limit normalised field value')\n",
    "    ax.set_ylabel('z (m)')\n",
    "    ax.grid(ls='--')\n",
    "    ax.legend(fontsize=8,loc='upper right')\n",
    "    zmin, zmax = int(L.zlow), int(L.zhigh)\n",
    "    ax.set_yticks(range(zmin,zmax))\n",
    "    ax.set_ylim(zmin,zmax)\n",
    "    ax.set_title(L.title, fontsize=10)\n",
    "    \n",
    "fig.tight_layout(w_pad=2)\n",
    "# fig.savefig('../plots/k1 k2 plots.png', dpi=100)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e436e9f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vary nsap and $k_2$ for a <u>single</u> source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cb52a5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d6fb55195d436dbed8c5c1700f017d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,3,figsize=(9,12))\n",
    "for i, nsap in enumerate([3,5]):\n",
    "    for j, k2 in enumerate([2, 1, 0.5]):\n",
    "        \n",
    "        # Calculate the assessments\n",
    "        L = calc_ass(h=2, nsap=nsap, fMHz=400,\n",
    "                     zlow=0, zhigh=20, dz=0.01,\n",
    "                     k1s=1, k2s=k2,\n",
    "                     zs=10)\n",
    "        \n",
    "        # Create the plots \n",
    "        ax = axes[i,j]\n",
    "        for lass, label in zip(L.lass, L.labels):\n",
    "            ax.plot(lass, L.z, alpha=0.7, label=label)\n",
    "        ax.set_xlabel('Limit normalised field value')\n",
    "        ax.set_ylabel('z (m)')\n",
    "        ax.grid(ls='--')\n",
    "        ax.legend(fontsize=8,loc='upper right')\n",
    "        zmin, zmax = int(L.zlow), int(L.zhigh)\n",
    "        ax.set_yticks(range(zmin,zmax))\n",
    "        ax.set_ylim(zmin,zmax)\n",
    "        ax.set_title(L.title,fontsize=10)\n",
    "        \n",
    "    fig.tight_layout(h_pad=4,w_pad=2)\n",
    "\n",
    "# fig.savefig('../plots/nsap k2 plots 1source.png', dpi=100)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42601dac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vary nsap and $k_2$ for <u>two</u> sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b430f1ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829f45335d5743dfaf5be2f3b7e6cf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,3,figsize=(9,12))\n",
    "for i, nsap in enumerate([3,5]):\n",
    "    for j, k2 in enumerate([2, 1, 0.5]):\n",
    "\n",
    "        # Calculate the assessments\n",
    "        L = calc_ass(h=2, nsap=nsap, fMHz=400,\n",
    "                     zlow=0, zhigh=20, dz=0.01,\n",
    "                     k1s=[1]*2, k2s=[k2]*2,\n",
    "                     zs=[7,13])\n",
    "        \n",
    "        # Create the plots\n",
    "        ax = axes[i,j]\n",
    "        for lass, label in zip(L.lass, L.labels):\n",
    "            ax.plot(lass, L.z, alpha=0.7, label=label)\n",
    "        ax.set_xlabel('Limit normalised field value')\n",
    "        ax.set_ylabel('z (m)')\n",
    "        ax.grid(ls='--')\n",
    "        ax.legend(fontsize=8,loc='upper right')\n",
    "        zmin, zmax = int(L.zlow), int(L.zhigh)\n",
    "        ax.set_yticks(range(zmin,zmax))\n",
    "        ax.set_ylim(zmin,zmax)\n",
    "        ax.set_title(L.title)\n",
    "    fig.tight_layout(h_pad=4,w_pad=2)\n",
    "\n",
    "# fig.savefig('../plots/nsap k2 plots 2source.png', dpi=100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95c643f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scratch\n",
    "*for testing out code ...*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
